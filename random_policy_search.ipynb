{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Finding best policy by brute force\n",
    "On this example we will do the simplest way of finding a policy for the cart pole problem, by brute force. This problem is simple because the state space and action space is small.\n",
    "\n",
    "#### State Space (1x4 vector)\n",
    "\n",
    "Num | Observation | Min | Max\n",
    "---|---|---|---\n",
    "0 | Cart Position | -2.4 | 2.4\n",
    "1 | Cart Velocity | -Inf | Inf\n",
    "2 | Pole Angle | ~ -41.8&deg; | ~ 41.8&deg;\n",
    "3 | Pole Velocity At Tip | -Inf | Inf\n",
    "\n",
    "#### Action space (1x2 vector)\n",
    "\n",
    "Num | Action\n",
    "--- | ---\n",
    "0 | Push cart to the left\n",
    "1 | Push cart to the right\n",
    "\n",
    "#### Search Space\n",
    "On this problem the search space is 8 because the action space has 2 elements and the state space 4 elements:\n",
    "$$len(\\text{S}_{\\text{1x4}}) . len(\\text{A}_\\text{1x2})$$\n",
    "\n",
    "#### Episode Termination\n",
    "* Pole Angle is more than ±12°\n",
    "* Cart Position is more than ±2.4 (center of the cart reaches the edge of the display)\n",
    "* Episode length is greater than 200\n",
    "\n",
    "### References\n",
    "* https://github.com/openai/gym/wiki/CartPole-v0\n",
    "* https://medium.com/@m.alzantot/deep-reinforcement-learning-demystified-episode-0-2198c05a6124\n",
    "* https://ray.readthedocs.io/en/latest/index.html\n",
    "* https://bair.berkeley.edu/blog/2018/01/09/ray/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Libraries and paramters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "# Only log errors\n",
    "gym.logger.set_level(40)\n",
    "\n",
    "# Policies to generate\n",
    "n_policy = 50000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Policy\n",
    "On this case our parametrized policy will receive our state $S_\\text{1x4}$ and do a dot product with it's internal set of parameters $\\theta_{1x4}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/leonardoaraujo/anaconda3/lib/python3.8/site-packages/ipykernel/ipkernel.py:287: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
      "  and should_run_async(code)\n"
     ]
    }
   ],
   "source": [
    "# Generate random 1x4 vector for the policy parameters\n",
    "def gen_random_policy_params():\n",
    "    return (np.random.uniform(-1,1, size=4).astype(np.float32))\n",
    "\n",
    "# Evaluate a policy given it's parameters and some state\n",
    "def policy(policy_params, state):\n",
    "    # It's basically a linear model\n",
    "    if np.dot(policy_params, state) > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate a list of possilbe policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated list of 50000 policies parameters\n"
     ]
    }
   ],
   "source": [
    "policy_params_list = [gen_random_policy_params() for _ in range(n_policy)]\n",
    "print('Generated list of %d policies parameters' % len(policy_params_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Policy\n",
    "This function basically run a policy during "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_policy_episode(policy_params, render=False):\n",
    "    # Crete environment\n",
    "    env = gym.make('CartPole-v0')\n",
    "    state = env.reset()\n",
    "    # Total rewards from eposide\n",
    "    total_reward_episode = 0\n",
    "    while True:\n",
    "        if render:\n",
    "            env.render()\n",
    "        selected_action = policy(policy_params, state)\n",
    "        state, reward, done, _ = env.step(selected_action)\n",
    "        total_reward_episode += reward\n",
    "        if done:\n",
    "            break\n",
    "    return total_reward_episode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Search for Policies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 41.1 s, sys: 281 ms, total: 41.4 s\n",
      "Wall time: 41.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Evaluate the policies on in the environment\n",
    "scores_list = [evaluate_policy_episode(p) for p in policy_params_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Best Policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best policy score = 200\n",
      "Found best policy with params: [-0.7618115   0.62916756  0.8967531   0.8483351 ]\n",
      "Total rewards on best policy: 200.0\n"
     ]
    }
   ],
   "source": [
    "# Select the best policy from the score list.\n",
    "best_score = max(scores_list)\n",
    "print('Best policy score = %d' % best_score)\n",
    "\n",
    "best_policy_params= policy_params_list[np.argmax(scores_list)]\n",
    "print('Found best policy with params:', best_policy_params)\n",
    "\n",
    "# Run best policy [0.32896566 0.56930596 0.8278743  0.43927363]\n",
    "total_rewards_best_policy = evaluate_policy_episode(best_policy_params, render=True);\n",
    "print('Total rewards on best policy:', total_rewards_best_policy)\n",
    "\n",
    "if total_rewards_best_policy != best_score:\n",
    "    print('Something went wrong')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
